---
title: "Lab Week 8"
author: "EM August-Schmidt"
date: "March 8, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Load the packages
```{r}
library(tidyverse) # for ggplotting
library(sf) # for reading in spatial shape file data
library(spatstat) # for point pattern analysis
library(maptools)
library(leaflet) # for making interactive (base) map plots
library(tmap) # for tmap plot
library(coin)
```

## Column graph of Texas oil spills 2010-2016
```{r}
oil_spills <- read_csv("oil_spills.csv")

# Subset dataframe with only data from Texas
df <- oil_spills %>%
  filter(`Accident State` == "TX" & `Accident Year` < 2017) %>%
  group_by(`Accident Year`) %>%
  summarise(Loss = sum(`Net Loss (Barrels)`))

colnames(df) <- c("Year", "Loss")

ggplot(df, aes(x=Year, y=Loss)) +
  geom_col()
```

## Leaflet plot of spill locations in Texas in 2016
```{r}
df_loc <- oil_spills %>%
  filter(`Accident State` == "TX" & `Accident Year` == 2016) %>%
  select(Latitude, Longitude, `Net Loss (Barrels)`)

colnames(df_loc) <- c("latitude","longitude", "net_loss")

oil_sf <- st_as_sf(df_loc, coords = c("longitude", "latitude"), crs = 4326) # convert data into spatial features data

# class(oil_sf) # now it's recognized as simple features data!

leaflet(oil_sf) %>%
  addTiles() %>%
  addMarkers()
```


## tmap plot with the Texas state shapefile
```{r}
states <- st_read(dsn = ".", layer = "states") # works because all files are in working directory. this reads in all files that begin 'states...'

tex_border <- states %>%
  filter(STATE_NAME == "Texas") %>%
  st_transform(4326) # give crs (coordinate reference system) for epsg value. This should match coordinate system that base map is in. 

st_crs(tex_border)

plot(tex_border)

tm_shape(tex_border) + 
  tm_polygons() +
  tm_shape(oil_sf) +
  tm_dots(size = 0.3)
```

## Convert the data to spatial points patterns (combination of point data and the bounding window)
```{r}
spill_sp <- as(oil_sf, "Spatial")

spill_ppp <- as(spill_sp, "ppp") # convert to point pattern data
class(spill_ppp)

tx_sp <- as(tex_border, "Spatial")
tx_owin <- as(tx_sp, "owin") #specifies texas border info as an Outer WINdow for point pattern analysis

all_ppp <- ppp(spill_ppp$x, spill_ppp$y, window = tx_owin)
# NB rejects any points in space that are not recognized as falling in the designated boundary window

```

## A kernel density plot for overlapping areas around plots
Beware you must choose an appropriate bandwidth of the sigma parameter (which affects the size of the grid cells) so that it is meaningful in terms of the true spatial extent of the data. 
```{r}
plot(density(all_ppp, sigma = 0.4))
```

## Quadrat test for spatial evenness
Again beware that the quadrant size has a big effect on the result of this test!! 

Significant p value means data are NOT evenly distributed
H0 = data ARE evenly distributed. 
```{r}
oil_qt <- quadrat.test(all_ppp, nx = 5, ny = 5)
oil_qt # The data are not spatially evenly distributed 
# nx = sets # horizontal regions, and ny sets # vertical regions

plot(all_ppp)
plot(oil_qt, add = TRUE, cex = 0.4)
```

# G-Function for Nearest Neighbor Analysis
We can calculate how many clusters have their nearest neighbor within lag distance r. 
If data are clustered, nearest neighbor will be closer than expected (than 'csr'). 
If data are evenly distributed, nearest neighbor will be farther than expected (random)

With g function, you can consider how close points are to nearest neighbor. 
You will need to do some data manipulation to determine what a meaningful r 'lag' value is. 

```{r}
r.lag <- seq(0,1, by = 0.01) # Creates a sequence from 0 to 1 by increments of 0.01

# Simulate csr distribute based on a Poisson distribution for comparison
oil_gfun <- envelope(all_ppp, fun = Gest, r = r.lag, nsim = 100)
View(oil_gfun)

ggplot(oil_gfun, aes(x= r, y= obs)) +
  geom_line(color = "black") +
  geom_line(aes(x = r, y = theo), color = "red")
```
Our data has a higher proportion of point pairs of nearest neighbors at shorter distances compared to CSR data. Meaning that on average, our data points have a closer neighbor than if data were truly randomly distributed. 

Include r values up to the max distance between nearest neighbors. 

## Nearest Neighbor using the L-function (Ripley's K, standardized)
With L and K functions, you draw increasing bubbles around each point and see what density of neighbors is as bubble gets larger. 

NB. These functions are MUCH more computationally intense!!
```{r}
r.lag.2 <- seq(0,4, by = 0.5) # this is a large increment chosen to speed up processing time

oil_lfun <- envelope(all_ppp, fun = Lest, r = r.lag.2, nsim = 20, global = TRUE)

ggplot(oil_lfun, aes(x = r.lag.2, y = obs)) +
  geom_line(color = "black") +
  geom_line(aes(x = r.lag.2, y = theo), color = "blue")
```
Both the L and G functions suggest that there tend to be observations that exist closer together than you'd expect with a random distribution (csr) -- ie CLUSTERED data. 

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
